{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdug1981/proyecto_final/blob/main/Proyecto_final_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Vision_producto](https://github.com/jdug1981/proyecto_final/blob/main/PRODUCT%20VISION%20BOARD.png?raw=true)"
      ],
      "metadata": {
        "id": "GXwX7TCrj9r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PROYECTO INTEGRADOR FINAL: BANK TELEMARKETING**\n",
        "El objetivo es predecir si un cliente se suscribirá a un depósito a plazo fijo que se le ofrece mediante una campaña de telemarketing.\n",
        "\n",
        "Para ello se propone crear un modelo de clasificación de aprendizaje automático con la finalidad poder usarlo en una población definida por un banco minorista de Portugal en el contexto de la recesión global del año 2008.\n",
        "[Link Product Vision Board](https://github.com/jdug1981/proyecto_final/blob/main/PRODUCT%20VISION%20BOARD.png?raw=true)"
      ],
      "metadata": {
        "id": "JoqZS4w6lqWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DESCRIPCION DE LOS DATOS**\n",
        "**1. Información Importante:**\n",
        "\n",
        "Los datos están relacionados con campañas de marketing directo de una entidad bancaria portuguesa. Las campañas de marketing se basaron en llamadas telefónicas. A menudo, se requería más de un contacto con el mismo cliente, para poder saber si el cliente se suscribiría a un depósito a plazo fijo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**2. Objetivo:**\n",
        "\n",
        "El objetivo es diseñar un modelo de clasificación para predecir si el cliente suscribirá un depósito a plazo (variable y).\n",
        "\n",
        "**3. Número de Instancias:**\n",
        "\n",
        "45211 for bank-full.csv (4521 for bank.csv)\n",
        "\n",
        "**4. Número de atributos:**\n",
        "\n",
        " 16 varaibles de entrada\n",
        "\n",
        " 1 variable de salida o variable Objetivo\n",
        "\n",
        "\n",
        "**5. Información sobre las Variables:**\n",
        "\n",
        "**Variables de Entrada**\n",
        "1. age: Edad del cliente (numérico).\n",
        "\n",
        "2. job: Tipo de empleo del cliente (categórico): \"admin.\", \"unknown\", \"unemployed\", \"management\", \"housemaid\", \"entrepreneur\", \"student\", \"blue-collar\", \"self-employed\", \"retired\", \"technician\", \"services\".\n",
        "\n",
        "3. marital: Estado civil del cliente (categórico): \"married\", \"divorced\", \"single\" (Nota: \"divorced\" significa divorciado o viudo).\n",
        "\n",
        "4. education: Nivel de educación del cliente (categórico): \"unknown\", \"secondary\", \"primary\", \"tertiary\".\n",
        "\n",
        "5. default: ¿Tiene el cliente crédito en mora? (binario): \"yes\", \"no\".\n",
        "\n",
        "6. balance: Saldo promedio anual, en euros, del cliente (numérico).\n",
        "\n",
        "7. housing: ¿Tiene el cliente un préstamo hipotecario? (binario): \"yes\", \"no\".\n",
        "\n",
        "8. loan: ¿Tiene el cliente un préstamo personal? (binario): \"yes\", \"no\".\n",
        "\n",
        "9. contact: Tipo de comunicación de contacto (categórico) relacionado con el último contacto de la campaña actual: \"unknown\", \"telephone\", \"cellular\".\n",
        "\n",
        "10. day: Último día del mes en que se realizó el último contacto (numérico).\n",
        "\n",
        "11. month: Último mes del año en que se realizó el último contacto (categórico): \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\".\n",
        "\n",
        "12. duration: Duración del último contacto en segundos (numérico).\n",
        "\n",
        "13. campaign: Número de contactos realizados durante esta campaña y para este cliente (numérico, incluye el último contacto).\n",
        "\n",
        "14. pdays: Número de días transcurridos desde el último contacto de una campaña anterior con el cliente (numérico, -1 significa que el cliente no fue contactado anteriormente).\n",
        "\n",
        "15. previous: Número de contactos realizados antes de esta campaña y para este cliente (numérico).\n",
        "\n",
        "16. poutcome: Resultado de la campaña de marketing anterior (categórico): \"unknown\", \"other\", \"failure\", \"success\".\n",
        "\n",
        "**Variable objetivo (target deseado):**\n",
        "\n",
        "17. y: ¿El cliente ha suscrito un depósito a plazo? (binario): \"yes\", \"no\".\n",
        "\n",
        "\n",
        "\n",
        "**6. Missing Attribute Values:**\n",
        "\n",
        "None\n"
      ],
      "metadata": {
        "id": "TQxC1Pcakcbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de Librerias\n",
        "!pip install pandas_profiling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import ydata_profiling\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "oFUUijF6jkR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693f5882-5813-4814-be2c-e1da70897756"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas_profiling\n",
            "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ydata-profiling (from pandas_profiling)\n",
            "  Downloading ydata_profiling-4.3.1-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.0/353.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.11,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.10.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.5.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.10.11)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (6.0)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (3.1.2)\n",
            "Collecting visions[type_image_path]==0.7.5 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.22.4)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (2.27.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (4.65.0)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.12.2)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.13.5)\n",
            "Collecting typeguard<3,>=2.13.2 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wordcloud>=1.9.1 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading wordcloud-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.4/455.4 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dacite>=1.8 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (8.4.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (3.1)\n",
            "Collecting tangled-up-in-unicode>=0.0.4 (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling)\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas_profiling) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2.1,>1.1->ydata-profiling->pandas_profiling) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas_profiling) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling->pandas_profiling) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (3.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas_profiling) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling->pandas_profiling) (1.16.0)\n",
            "Building wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=ee97a416af62fdda5fbaa3b2dcc6440e6765ea02eb018249431502799a9e9351\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin, typeguard, tangled-up-in-unicode, multimethod, dacite, imagehash, wordcloud, visions, phik, ydata-profiling, pandas_profiling\n",
            "  Attempting uninstall: wordcloud\n",
            "    Found existing installation: wordcloud 1.8.2.2\n",
            "    Uninstalling wordcloud-1.8.2.2:\n",
            "      Successfully uninstalled wordcloud-1.8.2.2\n",
            "Successfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.9.1 pandas_profiling-3.6.6 phik-0.12.3 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 visions-0.7.5 wordcloud-1.9.2 ydata-profiling-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explorar los datos para obtener información"
      ],
      "metadata": {
        "id": "aNGcAdRuprnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mainpath = \"bank_full.csv\"\n",
        "data = pd.read_csv(mainpath,sep=\";\")\n"
      ],
      "metadata": {
        "id": "bOvyPM1qpnFN",
        "outputId": "61251aeb-78e7-4228-acfd-9697098d4651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-10285f6de59a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmainpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bank_full.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bank_full.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar los datos:\n",
        "print(data.shape)\n",
        "# Validar la data de forma general\n",
        "data.head()"
      ],
      "metadata": {
        "id": "-WkadROOp0pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "luGzGep_mgt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observaciones:**\n",
        "\n",
        "La muestra tiene:\n",
        "\n",
        "45,211 instancias\n",
        "\n",
        "17 variables ( columnas).\n",
        "\n",
        "  - 10 variables categóricas\n",
        "\n",
        "  - 7 variables numéricas\n",
        "\n",
        "La variable Objetivo es categorica binaria: yes / no\n",
        "\n",
        "No hay valores missing\n"
      ],
      "metadata": {
        "id": "S2fY1psDwWkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Análisis de la Variable Objetivo (y)\n",
        "¿El cliente invirtió en un depósito a plazo fijo? : yes / no\n"
      ],
      "metadata": {
        "id": "muz0a77sVE2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#La variable Objetivo de tipo categórica se mapea en 0=no , yes=1\n",
        "data[\"y\"].unique()\n",
        "data[\"y\"]=data[\"y\"].map({'no':0, 'yes':1})\n",
        "data.info()"
      ],
      "metadata": {
        "id": "FJ2Nw4krLHmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizando la distribución de la variable objetivo.\n",
        "sns.countplot(x='y', data = data, palette = 'hls')"
      ],
      "metadata": {
        "id": "8HFfJAgKT0dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Media de la variable objetivo\n",
        "\n",
        "print(\"Media de Y: \", data.y.mean(). round(3))\n",
        "# Distribución de frecuencias de las respuestas a la suscripción de depósitos a plazo fijo (y)\n",
        "frecuencias = data.groupby('y').agg({'y': ['count',  lambda x: 100*x.size/len(data)]})\n",
        "frecuencias.columns = ['fi', 'hi%']\n",
        "print(\"\\nDistribución de frecuencias\")\n",
        "frecuencias\n"
      ],
      "metadata": {
        "id": "mGm9P5OuogFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Se observó:**\n",
        "\n",
        "1. *La variable objetivo es Categórica binaria.*  Por lo tanto, para el modelo de clasificación se codificó así:\n",
        "\n",
        "> 0='no'   No se suscribió a un depósito a plazo fijo.\n",
        "\n",
        "> 1='yes'  Si se suscribió a un depósito a plazo fijo.\n",
        "\n",
        "2. La Distribucipon de frecuencias de la variable objetiva nos muestra una data desbalanceada. 88.3% de la muestra no se suscribió a un depósito a plazo fijo. Esto se puede explicar por la desconfianza en el banco minorista dada la crisis del sistema financiero de Portugal el contexto de la crisis financiera del 2008.\n",
        "\n",
        "3. La media 0.117, nos indica que en promedio se suscribieron 12 de cada 100. Lo cual es bajo dado el desbalanceo de la data.\n"
      ],
      "metadata": {
        "id": "Qvd9C0-axkDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1. Análisis de las variables categóricas"
      ],
      "metadata": {
        "id": "_cwCPWUsqfsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['y','pdays']).size()"
      ],
      "metadata": {
        "id": "P6b_fPWBZR9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de variables categóricas\n",
        "variables_categoricas = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Lista de Variables Categóricas: \",variables_categoricas,\"\\n\")\n",
        "# Seleccionamos un subconjunto del dataset que sólo incluya las variables categóricas.\n",
        "categorical_columns =data.select_dtypes(include=['object'])\n",
        "categorical_columns.describe().transpose()"
      ],
      "metadata": {
        "id": "GaYxgOCeqXMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma de freciencias de las variables categóricas\n",
        "for column in categorical_columns:\n",
        "    category_counts = data[column].value_counts(normalize=True)\n",
        "    # Calcular las frecuencias relativas\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.bar(category_counts.index, category_counts.values)\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frecuencia Relativa')\n",
        "    plt.title(f\"Gráfico de barras - {column}\")\n",
        "    plt.xticks(rotation=30)\n",
        "\n",
        "    # Mostrar las frecuencias relativas en las etiquetas de las barras\n",
        "    for i, v in enumerate(category_counts.values):\n",
        "        plt.text(i, v, f'{v:.2%}', ha='center', va='bottom')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FW-CLYkStCgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análisis de la relación entre variables categóricas y una variable objetivo**\n",
        "\n",
        " Tabla de contingencia."
      ],
      "metadata": {
        "id": "gMN1qJzJd_zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_categorial(column):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    sns.countplot(data=data, x=column,hue='y')\n",
        "    plt.xticks(rotation='vertical')\n",
        "    plt.show()\n",
        "\n",
        "column_cat = data.select_dtypes(include='object').columns\n",
        "\n",
        "for _ in column_cat:\n",
        "    plot_categorial(_)"
      ],
      "metadata": {
        "id": "y5i9IvO1w4pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploración de variables categóricas\n",
        "# Con este análisis detectamos las relaciones que puede tener c/u de las variables vs la variable objetivo.\n",
        "for column in categorical_columns:\n",
        "  print(\"\\n\")\n",
        "  print(data.groupby(column).agg(count=('y', 'count'), hi=('y', 'mean')).sort_values(by=\"hi\", ascending=False))\n"
      ],
      "metadata": {
        "id": "7Ii1qdsNFyTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Se observó:**\n",
        "Analizando la relación de las variables categóricas con la variable objetivo (y), tenemos:\n",
        "\n",
        "1. En **Job:** La categoría \"*student*\" tiene la mayor probabilidad (28.7%) de suscribir un depósito a plazo fijo.\n",
        "2. En **marital:** La categoría \"*single*\" tiene la mayor probabilidad (14.9%) de suscribir un depósito a plazo fijo.     \n",
        "3. En **education:** La categoría \"*tertiary*\" tiene la mayor probabilidad (15%) de suscribir un depósito a plazo fijo.           \n"
      ],
      "metadata": {
        "id": "jUFlgGVi8r3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Análisis de la variable numérica"
      ],
      "metadata": {
        "id": "nu4LW12lrt9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar las variables numéricas utilizando el atributo dtypes\n",
        "variables_numericas = data.select_dtypes(include=['number']).columns.tolist()\n",
        "variables_numericas"
      ],
      "metadata": {
        "id": "DtJkgaDNgR2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificar las variables numéricas utilizando el atributo dtypes\n",
        "variables_numericas = data.select_dtypes(include=['number']).columns.tolist()\n",
        "print(\"Lista de Variables Numéricas:\",variables_numericas,\"\\n\")\n",
        "#  Seleccionamos un subconjunto del dataset que solo incluye a las variables numéricas\n",
        "numeric_columns = data.select_dtypes(include=['int64', 'float'])\n",
        "numeric_columns.describe().transpose()"
      ],
      "metadata": {
        "id": "YUonzUi2rlZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['y','pdays']).size()\n",
        "# Eliminar pdays muchos negativos"
      ],
      "metadata": {
        "id": "mGb_6RtfbUUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar gráficas individuales boxplot pues las variables numéricas.\n",
        "# están en rangos diferentes\n",
        "#cols_num = ['age', 'duration', 'campaign', 'pdays', 'previous']\n",
        "cols_num =variables_numericas[:-1]\n",
        "fig, ax = plt.subplots(nrows=len(cols_num), ncols=1, figsize=(8,30))\n",
        "fig.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for i, col in enumerate(cols_num):\n",
        "    sns.boxplot(x=col, data=data, ax=ax[i])\n",
        "    ax[i].set_title(col)"
      ],
      "metadata": {
        "id": "ASrOp9xTyYgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Selección de muestras"
      ],
      "metadata": {
        "id": "lWhLIgpazICr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestreo\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data,\n",
        "                               stratify = data['y'],\n",
        "                               train_size=0.7,\n",
        "                               random_state=234)"
      ],
      "metadata": {
        "id": "JOwKVsNqwgCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tamaño del total de datos: {len(data)}\")\n",
        "print(f\"Tamaño de train: {len(train)}\")\n",
        "print(f\"Tamaño de test: {len(test)}\")"
      ],
      "metadata": {
        "id": "C2JDzS-yzQPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pre selección de variables"
      ],
      "metadata": {
        "id": "PRN2SF2p4dO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dando formato a nuestra tabla resumen\n",
        "pdResume = train.describe().transpose()\n",
        "# Ahora el nuevo index será el campo \"feature\"\n",
        "pdResume[['missing_rate']] = 1 - pdResume[['count']]/train.shape[0]\n",
        "pdResume.sort_values(by = 'missing_rate', ascending = False, inplace = True)\n",
        "\n",
        "pdResume.reset_index(inplace = True)\n",
        "pdResume.rename(columns = {'index' : 'feature',\n",
        "                           '25%' : 'Q1',\n",
        "                           '50%' : 'median',\n",
        "                           '75%' : 'Q3'}, inplace = True)\n",
        "\n",
        "pdResume"
      ],
      "metadata": {
        "id": "nxfvcbjd4hNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ejecuta este comando, pero en realidad como la data ya está trabajada o sin na, entonces no se elimina ningún registro\n",
        "data.dropna(inplace=True)\n",
        "data.info()"
      ],
      "metadata": {
        "id": "uSNDNgHQ4t8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables_categoricas = train.select_dtypes(include=['object']).columns.tolist()\n",
        "cols_cat=variables_categoricas+['y']\n",
        "print(\"Lista de Variables Categóricas: \",variables_categoricas,\"\\n\")\n",
        "print(\"Lista de Variables Categóricas: \",cols_cat,\"\\n\")"
      ],
      "metadata": {
        "id": "GaQKhkG69N6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hemos validado que hay filas repetidas...Se eliminarán 12 filas.\n",
        "print(f'Tamaño del set antes de eliminar las filas repetidas: {data.shape}')\n",
        "data.drop_duplicates(inplace=True)\n",
        "print(f'Tamaño del set después de eliminar las filas repetidas: {data.shape}')"
      ],
      "metadata": {
        "id": "Q7IjXnA65JmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Tratamiento de variables"
      ],
      "metadata": {
        "id": "vVTR-LV15PRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Tratamiento de Variables Numéricas"
      ],
      "metadata": {
        "id": "6tTaBxvg6yUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de outliers por RIC\n",
        "\n",
        "# Calculando los intervalos RIC\n",
        "\n",
        "pdResume['ric'] = pdResume['Q3'] - pdResume['Q1']\n",
        "\n",
        "pdResume['min_ric'] = pdResume['Q1'] - 1.5*pdResume['ric']\n",
        "pdResume['max_ric'] = pdResume['Q3'] + 1.5*pdResume['ric']\n",
        "\n",
        "pdResume.head(10)"
      ],
      "metadata": {
        "id": "WWDDJFIE65ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de outliers por RIC\n",
        "\n",
        "for col in pdResume.feature.tolist():\n",
        "  desc = pdResume.loc[pdResume.feature == col]\n",
        "\n",
        "  lower_limit = desc.min_ric.values[0]\n",
        "  upper_limit = desc.max_ric.values[0]\n",
        "  if col!='y':\n",
        "    train[col + '_tric'] = train[col].apply(lambda x: lower_limit if x <= lower_limit else\n",
        "                                                    upper_limit if x >= upper_limit else\n",
        "                                                    x)\n",
        "    test[col + '_tric'] = test[col].apply(lambda x: lower_limit if x <= lower_limit else\n",
        "                                                    upper_limit if x >= upper_limit else\n",
        "                                                    x)\n",
        "\n",
        "\n",
        "\n",
        "train.info()"
      ],
      "metadata": {
        "id": "YSJIs51y8b5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(variables_numericas[:-1])\n",
        "\n",
        "variables_numericas_ric = [x + '_tric' for x in variables_numericas[:-1] ]\n",
        "variables_numericas_ric"
      ],
      "metadata": {
        "id": "kEdB0SX--DP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Tratamiento de Variables Categóricas"
      ],
      "metadata": {
        "id": "O80rrn7T70d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'job' in train.columns.tolist():\n",
        "  print(train['job'].value_counts())"
      ],
      "metadata": {
        "id": "IUqElIcy5OAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'job' in train.columns.tolist():\n",
        "  train['job'].drop_duplicates()"
      ],
      "metadata": {
        "id": "gqyt0aZT5dOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear las categorías a los nuevos valores\n",
        "mapping = {\n",
        "    'management': 'Estable',\n",
        "    'services': 'Inestable',\n",
        "    'blue-collar': 'Inestable',\n",
        "    'technician': 'Moderado',\n",
        "    'entrepreneur': 'Moderado',\n",
        "    'student': 'Variable',\n",
        "    'retired': 'Estable',\n",
        "    'admin.': 'Estable',\n",
        "    'housemaid': 'Inestable',\n",
        "    'self-employed': 'Moderado',\n",
        "    'unemployed': 'Inestable',\n",
        "    'unknown': 'Variable'\n",
        "}\n",
        "if 'job' in train.columns.tolist():\n",
        "  # EN TRAIN: Crear la nueva columna \"financial-stability\" utilizando el mapeo de categorías\n",
        "    train['financial-stability'] = train['job'].map(mapping)\n",
        "\n",
        "        # Eliminar la columna \"JOB\" si ya no es necesaria\n",
        "    train.drop('job', axis=1, inplace=True)\n",
        "# EN TEST: Crear la nueva columna \"financial-stability\" utilizando el mapeo de categorías\n",
        "    test['financial-stability'] = test['job'].map(mapping)\n",
        "\n",
        "# Eliminar la columna \"JOB\" si ya no es necesaria\n",
        "    test.drop('job', axis=1, inplace=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PktdUXE1IswJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train.info()"
      ],
      "metadata": {
        "id": "iqPsbOStPd4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test.info()"
      ],
      "metadata": {
        "id": "GDN_nHSBDjEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'job' not in train.columns.tolist():\n",
        "  print(train['financial-stability'].drop_duplicates())\n"
      ],
      "metadata": {
        "id": "XwhruDkqQ1R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables_categoricas = train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Lista de Variables Categóricas: \",variables_categoricas,\"\\n\")"
      ],
      "metadata": {
        "id": "UQZlQZGrzMFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "JXIJGOKnawhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tratamiento con Target Encoder\n",
        "# Se trabajará una consolidación con la variable \"job\"\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "encoder = TargetEncoder(handle_unknown = 'infrequent_if_exist')\n",
        "encoder.fit(train[variables_categoricas].astype('category'), train['y'])"
      ],
      "metadata": {
        "id": "5k1ktV6BaL0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TargetEncoder(cols=['financial-stability',\n",
        " 'marital',\n",
        " 'education',\n",
        " 'default',\n",
        " 'housing',\n",
        " 'loan',\n",
        " 'contact',\n",
        " 'month',\n",
        " 'poutcome'],\n",
        "              handle_unknown='infrequent_if_exist')"
      ],
      "metadata": {
        "id": "8pmEr7nWaS_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train[[x + '_coded' for x in variables_categoricas]] = encoder.transform(train[variables_categoricas].astype('category'))\n",
        "test[[x + '_coded' for x in variables_categoricas]] = encoder.transform(test[variables_categoricas].astype('category'))"
      ],
      "metadata": {
        "id": "q7sogaJCa3Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train[['financial-stability', 'financial-stability_coded']].head(10)"
      ],
      "metadata": {
        "id": "f-bL3sr0a5_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "rbhcbU0RdHbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis Univariado"
      ],
      "metadata": {
        "id": "swV-yIkCbGTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features_coded = [x + '_coded' for x in variables_categoricas]\n",
        "categorical_features_coded"
      ],
      "metadata": {
        "id": "1xCIKQ-ba8nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables_numericas_ric"
      ],
      "metadata": {
        "id": "lgihQcZoEPK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "univariate = train[variables_numericas_ric + categorical_features_coded+['y']].describe().transpose()\n",
        "univariate.reset_index(drop = False, inplace = True)\n",
        "\n",
        "univariate['missing_rate'] = 1 - univariate['count']/len(train)\n",
        "\n",
        "univariate.rename(columns = {'index' : 'feature',\n",
        "                             '25%': 'Q1',\n",
        "                             '50%' : 'median',\n",
        "                            '75%': 'Q3'}, inplace = True)\n",
        "univariate"
      ],
      "metadata": {
        "id": "vlX4ZZphbUwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tratamiento de outliers por percentiles\n",
        "\n",
        "# for col in univariate.feature.tolist():\n",
        "#   if col not in ['age']:\n",
        "#     print(col)\n",
        "#     desc = univariate.loc[univariate.feature == col]\n",
        "\n",
        "#     lower_limit = desc.p5.values[0]\n",
        "#     upper_limit = desc.p95.values[0]\n",
        "#     train[col + '_t'] = train[col].apply(lambda x: lower_limit if x <= lower_limit else\n",
        "#                                                     upper_limit if x >= upper_limit else\n",
        "#                                                     x)\n",
        "\n",
        "#     test[col + '_t'] = test[col].apply(lambda x: lower_limit if x <= lower_limit else\n",
        "#                                                upper_limit if x >= upper_limit else\n",
        "#                                                x)\n"
      ],
      "metadata": {
        "id": "8ccBGIN0bYX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(univariate.feature.tolist()))\n",
        "univariate.feature.tolist()"
      ],
      "metadata": {
        "id": "BQghdzTzcFcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train.columns.to_list()))\n",
        "train.columns.to_list()"
      ],
      "metadata": {
        "id": "OwQCn7UBXh_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.boxplot(x = train.age)"
      ],
      "metadata": {
        "id": "e-IpfSjkcl-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(x = train.age)"
      ],
      "metadata": {
        "id": "1Yj7TD3vrWKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x = train.age_tric)"
      ],
      "metadata": {
        "id": "wyuQGAUorer8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(x = train.age_tric, bins=4)"
      ],
      "metadata": {
        "id": "D01e-0cArnOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis Bivariado"
      ],
      "metadata": {
        "id": "skKytqycrSYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretizar variables\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "var = 'age'\n",
        "temp = train.copy()\n",
        "temp = temp.fillna(temp.mean())\n",
        "\n",
        "\n",
        "discretizer = KBinsDiscretizer(n_bins = 10,\n",
        "                               encode = 'ordinal',\n",
        "                               strategy = \"uniform\").fit(np.array(temp[var]).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "rqaGr-EHcplY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretizar variables\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "var = 'age_tric'\n",
        "temp = train.copy()\n",
        "temp[var]=temp[var]**4\n",
        "temp = temp.fillna(temp.mean())\n",
        "discretizer = KBinsDiscretizer(n_bins =4,\n",
        "                               encode = 'ordinal',\n",
        "                               strategy = \"uniform\").fit(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "temp[var + '_rango'] = discretizer.transform(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "# Interpretación del ratio de evento por tramo de variable numérica\n",
        "sns.lineplot(data = temp.groupby(var + '_rango').agg({'y': 'mean'}).reset_index(),\n",
        "             x = var + '_rango',\n",
        "             y = 'y')"
      ],
      "metadata": {
        "id": "FsxBs1JMfUwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretizar variables\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "var = 'balance_tric'\n",
        "temp = train.copy()\n",
        "temp[var]=temp[var]\n",
        "temp = temp.fillna(temp.mean())\n",
        "discretizer = KBinsDiscretizer(n_bins =4,\n",
        "                               encode = 'ordinal',\n",
        "                               strategy = \"uniform\").fit(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "temp[var + '_rango'] = discretizer.transform(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "# Interpretación del ratio de evento por tramo de variable numérica\n",
        "sns.lineplot(data = temp.groupby(var + '_rango').agg({'y': 'mean'}).reset_index(),\n",
        "             x = var + '_rango',\n",
        "             y = 'y')"
      ],
      "metadata": {
        "id": "zPIzCqPVh4lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretizar variables\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "var = 'duration_tric'\n",
        "temp = train.copy()\n",
        "temp[var]=temp[var]**2\n",
        "temp = temp.fillna(temp.mean())\n",
        "discretizer = KBinsDiscretizer(n_bins =4,\n",
        "                               encode = 'ordinal',\n",
        "                               strategy = \"uniform\").fit(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "temp[var + '_rango'] = discretizer.transform(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "# Interpretación del ratio de evento por tramo de variable numérica\n",
        "sns.lineplot(data = temp.groupby(var + '_rango').agg({'y': 'mean'}).reset_index(),\n",
        "             x = var + '_rango',\n",
        "             y = 'y')"
      ],
      "metadata": {
        "id": "FE0jzzQhiWUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretizar variables\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "var = 'day_tric'\n",
        "temp = train.copy()\n",
        "temp[var]=temp[var]**0.7\n",
        "temp = temp.fillna(temp.mean())\n",
        "discretizer = KBinsDiscretizer(n_bins =4,\n",
        "                               encode = 'ordinal',\n",
        "                               strategy = \"uniform\").fit(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "temp[var + '_rango'] = discretizer.transform(np.array(temp[var]).reshape(-1, 1))\n",
        "\n",
        "# Interpretación del ratio de evento por tramo de variable numérica\n",
        "sns.lineplot(data = temp.groupby(var + '_rango').agg({'y': 'mean'}).reset_index(),\n",
        "             x = var + '_rango',\n",
        "             y = 'y')"
      ],
      "metadata": {
        "id": "v16M3sa4xLSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "avzg26AWuUM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analisis de la realcion entre variables categoricas y target. Seleccion:\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Prueba de chi-cuadrado para evaluar la asociación\n",
        "for variable in categorical_features_coded:\n",
        "    crosstab = pd.crosstab(train[variable], train[\"y\"])\n",
        "    chi2, p_value, _, _ = chi2_contingency(crosstab)\n",
        "    print(f\"Variable: {variable}\")\n",
        "    print(f\"Estadístico de chi-cuadrado: {chi2}\")\n",
        "    print(f\"Valor p: {round(p_value,5)}\\n\")"
      ],
      "metadata": {
        "id": "UhSqGj7NlYYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como el p_value es menor a 5%=0.05 para todas las categoricas, entonces hay una fuerte relación entre las variables y su target."
      ],
      "metadata": {
        "id": "ASDhql-tqTJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "S7lb8Bu6gXro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamiento de Missing"
      ],
      "metadata": {
        "id": "KitYfqXlgX-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.fillna(train.median())\n",
        "test  = test.fillna(train.median())"
      ],
      "metadata": {
        "id": "x9EsmrXDga1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Selección de Variables"
      ],
      "metadata": {
        "id": "9LrZKkowg9dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Pre-Selección de Variables usando el GINI\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "dfgini = pd.DataFrame({'feature': variables_numericas_ric + categorical_features_coded,\n",
        "                       'gini': [roc_auc_score(temp.y, temp[col])*2-1 for col in variables_numericas_ric + categorical_features_coded]})\n",
        "\n",
        "dfgini['gini_abs'] = dfgini.gini.apply(lambda x: abs(x))\n",
        "\n",
        "dfgini.sort_values(by = 'gini_abs', ascending = False)"
      ],
      "metadata": {
        "id": "-k9Dc7nGg4gj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a2bc5377-8c95-49f6-e7f2-5526fa02657c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fd55de72926c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m dfgini = pd.DataFrame({'feature': variables_numericas_ric + categorical_features_coded,\n\u001b[0m\u001b[1;32m      6\u001b[0m                        'gini': [roc_auc_score(temp.y, temp[col])*2-1 for col in variables_numericas_ric + categorical_features_coded]})\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable con Relación inversa con el target:\n",
        "\n",
        "campaign_tric, day_tric,age_tric"
      ],
      "metadata": {
        "id": "xfMSJLk7n2qK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estandarización"
      ],
      "metadata": {
        "id": "4vTNTdUPg_cL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7ImfZong6mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64xW73bhhFTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística"
      ],
      "metadata": {
        "id": "ZFXTHyMUhF8l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pxVDAC3khIJ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}